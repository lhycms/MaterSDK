{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Extract parameters of force field from `checkpoint file(.pt)`, and store it as `hdf5 file(.h5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/liuhanyu/anaconda3/envs/mlff/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from matersdk.infer.pwmatmlff.deepmd.extractor import FFExtractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Custom parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. checkpoint文件的路径\n",
    "pt_path = \"/data/home/liuhanyu/hyliu/pwmat_demo/ff_files/demo2/checkpoint.pth.tar\"\n",
    "# 2. hdf5文件的路径\n",
    "hdf5_path = \"./test.h5\"\n",
    "# 3. num_embedding_nets = num_elements * num_elements\n",
    "num_embedding_nets = 4\n",
    "# 4. num_embedding_layer: embedding 的层数。 \n",
    "#   e.g.[25, 25, 25], num_embedding_layer = 3\n",
    "num_embedding_layers = 3\n",
    "# 5. num_fitting_nets = num_elements\n",
    "num_fitting_nets = 2\n",
    "# 6. num_fitting_nets: fitting 的层数\n",
    "#   e.g.[50, 50, 50], num_fitting_layer = 3\n",
    "num_fitting_layers = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 将force field的参数存储为hdf5文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_extract = FFExtractor(\n",
    "                pt_path=pt_path,\n",
    "                num_embedding_nets=num_embedding_nets,\n",
    "                num_embedding_layers=num_embedding_layers,\n",
    "                num_fitting_nets=num_fitting_nets,\n",
    "                num_fitting_layers=num_fitting_layers)\n",
    "\n",
    "ff_extract.save_hdf5_file(hdf5_path=hdf5_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 读取 hdf5 文件，获取字典对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dict:Dict[str, np.ndarray] = FFExtractor.get_hdf5_dict(hdf5_path=hdf5_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 查看 `Wij`, `Bi`, `Resnet block` 的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_net.0.bias.bias0: (1, 25)\n",
      "embedding_net.0.bias.bias1: (1, 25)\n",
      "embedding_net.0.bias.bias2: (1, 25)\n",
      "embedding_net.0.weights.weight0: (1, 25)\n",
      "embedding_net.0.weights.weight1: (25, 25)\n",
      "embedding_net.0.weights.weight2: (25, 25)\n",
      "embedding_net.1.bias.bias0: (1, 25)\n",
      "embedding_net.1.bias.bias1: (1, 25)\n",
      "embedding_net.1.bias.bias2: (1, 25)\n",
      "embedding_net.1.weights.weight0: (1, 25)\n",
      "embedding_net.1.weights.weight1: (25, 25)\n",
      "embedding_net.1.weights.weight2: (25, 25)\n",
      "embedding_net.2.bias.bias0: (1, 25)\n",
      "embedding_net.2.bias.bias1: (1, 25)\n",
      "embedding_net.2.bias.bias2: (1, 25)\n",
      "embedding_net.2.weights.weight0: (1, 25)\n",
      "embedding_net.2.weights.weight1: (25, 25)\n",
      "embedding_net.2.weights.weight2: (25, 25)\n",
      "embedding_net.3.bias.bias0: (1, 25)\n",
      "embedding_net.3.bias.bias1: (1, 25)\n",
      "embedding_net.3.bias.bias2: (1, 25)\n",
      "embedding_net.3.weights.weight0: (1, 25)\n",
      "embedding_net.3.weights.weight1: (25, 25)\n",
      "embedding_net.3.weights.weight2: (25, 25)\n",
      "embedding_sizes: (3,)\n",
      "fitting_net.0.bias.bias0: (1, 50)\n",
      "fitting_net.0.bias.bias1: (1, 50)\n",
      "fitting_net.0.bias.bias2: (1, 50)\n",
      "fitting_net.0.resnet_dt.resnet_dt1: (1, 50)\n",
      "fitting_net.0.resnet_dt.resnet_dt2: (1, 50)\n",
      "fitting_net.0.weights.weight0: (400, 50)\n",
      "fitting_net.0.weights.weight1: (50, 50)\n",
      "fitting_net.0.weights.weight2: (50, 50)\n",
      "fitting_net.1.bias.bias0: (1, 50)\n",
      "fitting_net.1.bias.bias1: (1, 50)\n",
      "fitting_net.1.bias.bias2: (1, 50)\n",
      "fitting_net.1.resnet_dt.resnet_dt1: (1, 50)\n",
      "fitting_net.1.resnet_dt.resnet_dt2: (1, 50)\n",
      "fitting_net.1.weights.weight0: (400, 50)\n",
      "fitting_net.1.weights.weight1: (50, 50)\n",
      "fitting_net.1.weights.weight2: (50, 50)\n",
      "fitting_sizes: (3,)\n"
     ]
    }
   ],
   "source": [
    "for tmp_key, tmp_value in hdf5_dict.items():\n",
    "    if type(tmp_value) == np.ndarray:\n",
    "        print(\"{0}: {1}\".format(tmp_key, tmp_value.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 查看 `M1`, `M2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 =  25\n",
      "M2 =  16\n"
     ]
    }
   ],
   "source": [
    "print(\"M1 = \", hdf5_dict[\"M1\"])\n",
    "print(\"M2 = \", hdf5_dict[\"M2\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. 查看 `embedding_sizes`, `fitting_sizes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_sizes =  [25 25 25]\n",
      "fitting_sizes =  [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "print(\"embedding_sizes = \", hdf5_dict[\"embedding_sizes\"])\n",
    "print(\"fitting_sizes = \", hdf5_dict[\"fitting_sizes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
